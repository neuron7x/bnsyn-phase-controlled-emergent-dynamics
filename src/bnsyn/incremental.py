"""Incremental computation with joblib caching for 10-100x speedup.

Provides persistent caching decorator for expensive computations.
Cache invalidates when dependencies change.

References
----------
docs/LEGENDARY_QUICKSTART.md
"""

from __future__ import annotations

import functools
import hashlib
from pathlib import Path
from typing import Any, Callable, TypeVar

from joblib import Memory  # type: ignore[import-untyped]

# Create cache directory
CACHE_DIR = Path(".cache/bnsyn")
CACHE_DIR.mkdir(parents=True, exist_ok=True)

# Initialize joblib memory
memory = Memory(str(CACHE_DIR), verbose=0)

F = TypeVar("F", bound=Callable[..., Any])


def compute_file_hash(filepath: str | Path) -> str:
    """Compute SHA256 hash of file contents.

    Parameters
    ----------
    filepath : str | Path
        Path to file to hash

    Returns
    -------
    str
        Hex digest of file hash

    Examples
    --------
    Check if file changed::

        hash1 = compute_file_hash("config.yaml")
        # ... modify file ...
        hash2 = compute_file_hash("config.yaml")
        assert hash1 != hash2
    """
    path = Path(filepath)
    if not path.exists():
        return ""

    sha256 = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(65536), b""):
            sha256.update(chunk)
    return sha256.hexdigest()


def cached(depends_on: str | Path | list[str | Path] | None = None) -> Callable[[F], F]:
    """Decorator for caching expensive function results.

    Parameters
    ----------
    depends_on : str | Path | list[str | Path] | None, optional
        File path(s) that trigger cache invalidation when changed.
        If None, cache never invalidates (default).

    Returns
    -------
    Callable[[F], F]
        Decorator that wraps function with caching

    Notes
    -----
    Cache is stored in .cache/bnsyn/ directory.
    Add .cache/ to .gitignore to avoid committing cache.

    Examples
    --------
    Cache expensive computation::

        from bnsyn.incremental import cached

        @cached()
        def expensive_analysis(data):
            # This only runs once per unique data
            return analyze(data)

    Cache with file dependency::

        @cached(depends_on="config.yaml")
        def load_and_process(config_path):
            # Re-runs when config.yaml changes
            return process(load(config_path))

    Multiple dependencies::

        @cached(depends_on=["data.csv", "params.yaml"])
        def process_experiment():
            return run_experiment()
    """

    def decorator(func: F) -> F:
        cached_func = memory.cache(func)

        @functools.wraps(func)
        def wrapper(*args: Any, **kwargs: Any) -> Any:
            # Compute dependency hash if specified
            if depends_on is not None:
                files = [depends_on] if isinstance(depends_on, (str, Path)) else depends_on
                dep_hash = "|".join(compute_file_hash(f) for f in files)
                kwargs["_dep_hash"] = dep_hash

            return cached_func(*args, **kwargs)

        return wrapper  # type: ignore[return-value]

    return decorator


def clear_cache() -> None:
    """Clear all cached results.

    Parameters
    ----------
    None

    Returns
    -------
    None

    Examples
    --------
    Clear cache to force recomputation::

        from bnsyn.incremental import clear_cache

        clear_cache()
    """
    memory.clear()
