$ sed -n "1,260p" pyproject.toml
[project]
name = "bnsyn"
version = "0.2.0"
description = "BN-Syn Thermostated Bio-AI System: AdEx + conductances + 3-factor plasticity + criticality control + temperature-gated consolidation"
requires-python = ">=3.11"
readme = "README.md"
license = "MIT"
license-files = ["LICENSE"]
authors = [{name="BN-Syn Contributors"}]
dependencies = [
  "numpy==2.4.1",
  "pydantic==2.12.5",
  "scipy==1.17.0",
  "jsonschema==4.26.0",
  "joblib==1.4.2",
]

[project.optional-dependencies]
dev = [
  "hypothesis==6.151.5",
  "pytest==9.0.2",
  "pytest-cov==7.0.0",
  "pyyaml==6.0.3",
  "ruff==0.15.0",
  "mypy==1.19.1",
  "pylint==3.3.5",
  "pydocstyle==6.3.0",
  "bandit==1.9.3",
  "validate-pyproject==0.25",
  "pre-commit==4.5.1",
  "pip-audit==2.10.0",
  "psutil==7.2.2",
  "sphinx==9.0.4",
  "sphinx-autodoc-typehints==3.6.1",
  "myst-parser==5.0.0",
  "furo==2025.12.19",
  "sphinx-copybutton==0.5.2",
]

test = [
  "hypothesis==6.151.5",
  "pytest==9.0.2",
  "pytest-cov==7.0.0",
  "pyyaml==6.0.3",
  "psutil==7.2.2",
]

viz = [
  "matplotlib==3.10.8",
  "pillow==12.1.0",
  "streamlit==1.42.1",
  "plotly==6.5.2",
]

jax = [
  "jax==0.6.0",
  "jaxlib==0.9.0",
]

torch = [
  "torch==2.10.0",
]

accelerators = [
  "bnsyn[jax]",
  "bnsyn[torch]",
]

[project.scripts]
bnsyn = "bnsyn.cli:main"

[build-system]
requires = ["setuptools==79.0.1"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
package-dir = {"" = "src"}

[tool.pytest.ini_options]
addopts = "-q --strict-markers"
testpaths = ["tests"]
markers = [
  "smoke: fast critical-path tests",
  "validation: slow statistical/large-N validation tests (excluded from CI by default)",
  "benchmark: benchmark regression tests (excluded from mutation runs)",
  "performance: performance regression tests with timing assertions",
  "integration: integration tests requiring multiple components",
  "property: property-based tests using Hypothesis",
  "chaos: chaos engineering tests with fault injection",
]

[tool.hypothesis]
derandomize = true

[tool.hypothesis.profiles.ci]
max_examples = 200
deadline = 10000
print_blob = true

[tool.hypothesis.profiles.quick]
max_examples = 100
deadline = 5000
print_blob = true

[tool.hypothesis.profiles.thorough]
max_examples = 1000
deadline = 20000
print_blob = true

[tool.ruff]
line-length = 100
target-version = "py311"

[tool.mypy]
python_version = "3.11"
strict = true
warn_return_any = true
disallow_untyped_defs = true
disallow_untyped_calls = true
disallow_incomplete_defs = true
check_untyped_defs = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unused_configs = true
plugins = ["pydantic.mypy"]

# Optional visualization dependencies (no type stubs available)
[[tool.mypy.overrides]]
module = ["plotly.*", "streamlit.*", "matplotlib.*"]
ignore_missing_imports = true

[tool.pylint.main]
recursive = true
ignore-patterns = ["^test_.*\\.py$", "^conftest\\.py$"]
fail-under = 7.5

[tool.pylint.messages_control]
disable = [
  "import-error",
  "invalid-name",
  "broad-exception-caught",
  "useless-import-alias",
  "missing-function-docstring",
]

[tool.pylint.basic]
good-names = ["i", "j", "k", "V", "N", "w", "dt", "dx", "dy", "R", "E"]

[tool.pylint.design]
max-args = 15

[[tool.mypy.overrides]]
module = "scipy.*"
ignore_missing_imports = true

[[tool.mypy.overrides]]
module = "torch"
ignore_missing_imports = true

[[tool.mypy.overrides]]
module = "jax.*"
ignore_missing_imports = true

[tool.setuptools.packages.find]
where = ["src"]
$ sed -n "1,260p" Makefile
.PHONY: dev-setup quickstart-smoke dev-env-offline wheelhouse-build wheelhouse-validate wheelhouse-report wheelhouse-clean check test test-determinism test-validation coverage coverage-fast coverage-baseline coverage-gate quality format fix lint mypy ssot security clean docs validate-claims-coverage docs-evidence mutation mutation-ci mutation-baseline mutation-check mutation-check-strict release-readiness manifest manifest-validate manifest-check inventory inventory-check

LOCK_FILE ?= requirements-lock.txt
WHEELHOUSE_DIR ?= wheelhouse
PYTHON_VERSION ?= 3.11
WHEELHOUSE_REPORT ?= artifacts/wheelhouse_report.json

dev-setup:
	python -m pip install --upgrade pip setuptools wheel
	python -m pip install -e ".[dev,test]"
	pre-commit install
	pre-commit autoupdate

quickstart-smoke:
	python -m scripts.check_quickstart_consistency
	python -m pip install -e .
	python -m pip show bnsyn
	bnsyn --help
	bnsyn sleep-stack --help
	bnsyn demo --steps 120 --dt-ms 0.1 --seed 123 --N 32 | python -c "import json,sys; data=json.load(sys.stdin); assert 'demo' in data, 'missing demo key'; print('quickstart demo output validated')"


wheelhouse-build:
	python -m scripts.build_wheelhouse build --lock-file $(LOCK_FILE) --wheelhouse $(WHEELHOUSE_DIR) --python-version $(PYTHON_VERSION)

wheelhouse-validate:
	python -m scripts.build_wheelhouse validate --lock-file $(LOCK_FILE) --wheelhouse $(WHEELHOUSE_DIR) --python-version $(PYTHON_VERSION) --report $(WHEELHOUSE_REPORT)

dev-env-offline: wheelhouse-validate
	python -m pip install --no-index --find-links $(WHEELHOUSE_DIR) -r $(LOCK_FILE)
	python -m pip install --no-index --find-links $(WHEELHOUSE_DIR) --no-deps -e .
	pre-commit install

wheelhouse-clean:
	rm -rf $(WHEELHOUSE_DIR) $(WHEELHOUSE_REPORT)

wheelhouse-report: wheelhouse-validate
	@echo "Wheelhouse report: $(WHEELHOUSE_REPORT)"

test:
	python -m pytest -m "not validation" -q

test-determinism:
	python -m pytest tests/test_determinism.py tests/test_properties_determinism.py -q

test-validation:
	python -m pytest -m validation -q

coverage:
	python -m pytest --cov=bnsyn --cov-report=term-missing:skip-covered --cov-report=xml:coverage.xml -q

coverage-fast:
	python -m pytest -m "not (validation or property)" --cov=bnsyn --cov-report=term-missing --cov-report=xml:coverage.xml -q

coverage-baseline: coverage
	python -m scripts.generate_coverage_baseline --coverage-xml coverage.xml --output quality/coverage_gate.json --minimum-percent 99.0

coverage-gate: coverage
	python -m scripts.check_coverage_gate --coverage-xml coverage.xml --baseline quality/coverage_gate.json


mutation:
	@echo "üß¨ Running mutation profile (reproducible local workflow step)..."
	@python -m pip install -e ".[test]" -q
	@python -m pip install mutmut==2.4.5 -q
	@python -m scripts.run_mutation_pipeline

mutation-ci:
	@echo "üß¨ Emitting mutation CI artifacts to local files..."
	@baseline_file=quality/mutation_baseline.json; \
	output_file=.mutation_ci_output; \
	summary_file=.mutation_ci_summary.md; \
	: > $$output_file; \
	: > $$summary_file; \
	GITHUB_OUTPUT=$$output_file GITHUB_STEP_SUMMARY=$$summary_file python -m scripts.mutation_ci_summary --baseline $$baseline_file --write-output --write-summary

mutation-baseline:
	@echo "üß¨ Running mutation testing to establish baseline..."
	@python -m pip install -e ".[test]" -q
	@python -m pip install mutmut==2.4.5 -q
	@python -m scripts.generate_mutation_baseline

mutation-check:
	@echo "üß¨ Running mutation testing against baseline..."
	@python -m pip install -e ".[test]" -q
	@python -m pip install mutmut==2.4.5 -q
	@rm -rf .mutmut-cache
	@python -c "import json; baseline=json.load(open('quality/mutation_baseline.json')); print(f\"Baseline: {baseline['baseline_score']}% (tolerance: ¬±{baseline['tolerance_delta']}%)\")"
	@python -m scripts.validate_mutation_baseline
	@python -m scripts.run_mutation_pipeline
	@python -m scripts.check_mutation_score --advisory

mutation-check-strict:
	@echo "üß¨ Running mutation testing against baseline (STRICT MODE)..."
	@python -m pip install -e ".[test]" -q
	@python -m pip install mutmut==2.4.5 -q
	@rm -rf .mutmut-cache
	@python -c "import json; baseline=json.load(open('quality/mutation_baseline.json')); print(f\"Baseline: {baseline['baseline_score']}% (tolerance: ¬±{baseline['tolerance_delta']}%)\")"
	@python -m scripts.validate_mutation_baseline
	@python -m scripts.run_mutation_pipeline
	@python -m scripts.check_mutation_score --strict

api-contract:
	python -m scripts.check_api_contract --baseline quality/api_contract_baseline.json

validate-api-maturity:
	python -m scripts.validate_api_maturity

quality: format lint mypy ssot security
	@echo "‚úÖ All quality checks passed"

format:
	ruff format .
	@echo "Formatted code"

fix:
	ruff check . --fix
	@echo "Fixed lint issues"

lint:
	ruff check .
	pylint src/bnsyn

mypy:
	mypy src --strict --config-file pyproject.toml

ssot:
	python -m scripts.validate_bibliography
	python -m scripts.validate_claims
	python -m scripts.scan_normative_tags
	python -m scripts.validate_pr_gates
	python -m scripts.validate_required_status_contexts
	python -m scripts.sync_required_status_contexts --check
	$(MAKE) inventory-check
	python -m scripts.validate_api_maturity
	$(MAKE) api-contract
	$(MAKE) manifest-check
	$(MAKE) traceability-check

validate-claims-coverage:
	python -m scripts.validate_claims_coverage --format markdown

docs-evidence:
	python -m scripts.generate_evidence_coverage

security:
	gitleaks detect --redact --verbose --source=.
	pip-audit --desc
	bandit -r src/ -ll

check: format lint mypy coverage ssot security
	@echo "‚úÖ All checks passed"

docs:
	python -m sphinx -b html docs docs/_build/html
	@echo "Docs built at docs/_build/html"

release-readiness:
	python -m scripts.release_readiness

manifest:
	python -m tools.manifest generate

manifest-validate:
	python -m tools.manifest validate

manifest-check: manifest manifest-validate
	git diff --exit-code -- .github/REPO_MANIFEST.md manifest/repo_manifest.computed.json

inventory:
	python tools/generate_inventory.py

inventory-check:
	python tools/generate_inventory.py --check

clean:
	find . -type d -name __pycache__ -exec rm -rf {} +
	find . -type d -name .pytest_cache -exec rm -rf {} +
	find . -type d -name .mypy_cache -exec rm -rf {} +
	find . -type d -name htmlcov -exec rm -rf {} +
	find . -type f -name .coverage -delete
	find . -type d -name "*.egg-info" -exec rm -rf {} +
	rm -f .mutmut-cache
	rm -rf $(WHEELHOUSE_DIR) $(WHEELHOUSE_REPORT)
	@echo "Cleaned temporary files"


traceability-check:
	python -m scripts.validate_traceability

public-surfaces:
	python -m scripts.discover_public_surfaces
$ rg -n "\[tool.pytest.ini_options\]|markers|validation|property" pyproject.toml
79:[tool.pytest.ini_options]
80:addopts = "-q --strict-markers"
82:markers = [
84:  "validation: slow statistical/large-N validation tests (excluded from CI by default)",
88:  "property: property-based tests using Hypothesis",
$ rg -n "assert True|pytest\.skip\(|@pytest\.mark\.skip|skip\(" tests
tests/test_mutation_counts_contract.py:49:        pytest.skip("Baseline not yet generated - run 'make mutation-baseline' first")
tests/test_verify_hypothesis_v2.py:36:        pytest.skip("Bundled v2 results not found (expected in CI)")
tests/test_verify_hypothesis_v2.py:65:        pytest.skip("Bundled v1 results not found")
tests/test_math_invariants.py:168:        pytest.skip("Hypothesis is required for property tests")
tests/test_math_invariants.py:172:        pytest.skip("Hypothesis is required for property tests")
tests/test_interactive_smoke.py:20:@pytest.mark.skipif(
tests/test_interactive_smoke.py:30:@pytest.mark.skipif(
tests/test_interactive_smoke.py:82:        pytest.skip("Example config not found")
tests/test_interactive_smoke.py:185:@pytest.mark.skipif(
tests/test_interactive_smoke.py:212:@pytest.mark.skipif(
tests/validation/test_viz_dashboard.py:114:    pytest.importorskip("matplotlib")
tests/validation/test_viz_dashboard.py:142:    pytest.importorskip("matplotlib")
$ rg -n "100/100|perfect|Synthetic|proxy|calibration" -g "*.md" docs claims .
./docs/benchmarks/SCHEMA.md:111:| `thermostat_exploration_mean` | - | Mean exploration proxy |
./docs/HYPOTHESIS.md:32:### Synthetic Input Protocol
./CALIBRATION_SUMMARY.md:4:Operational readiness is **100/100 (CALIBRATED)** with all gates G1‚ÄìG7 passing under deterministic fixtures and schema-validated outputs.
./CALIBRATION_SUMMARY.md:7:1. Synthetic fixtures still proxy real telemetry.
./CALIBRATION_SUMMARY.md:14:`python calibration_pack/harness/run_calibration.py`
./CALIBRATION_SUMMARY.md:15:`python calibration_pack/harness/build_report.py`
./CALIBRATION_SUMMARY.md:16:`python -m jsonschema -i CALIBRATION_REPORT.json calibration_pack/schemas/calibration_report.schema.json`
./CALIBRATION_SUMMARY.md:17:`python calibration_pack/harness/validate_summary.py`
./docs/math/MATH_SURFACES.md:7:- Component model surfaces explicitly defined by SPEC: AdEx neuron dynamics (P0-1), conductance synapses (P0-2), three-factor learning (P0-3), criticality control (P0-4), temperature gating (P1-5), consolidation (P1-6), energy regularization (P1-7), numerical methods (P2-8), determinism protocol (P2-9), calibration (P2-10), reference network simulator (P2-11), bench harness (P2-12).
./CONTRIBUTING.md:272:- P2-9: Calibration (bnsyn.calibration)
./docs/CRITICALITY_CONTROL_VS_MEASUREMENT.md:3:## Runtime control (proxy)
./docs/CRITICALITY_CONTROL_VS_MEASUREMENT.md:6:Example proxy:
./docs/CRITICALITY_CONTROL_VS_MEASUREMENT.md:7:- œÉ_proxy(k) = A(k) / (A(k-1) + Œµ)
./docs/CRITICALITY_CONTROL_VS_MEASUREMENT.md:10:- Label as **proxy** in code + docs.
./docs/CRITICALITY_CONTROL_VS_MEASUREMENT.md:11:- Avoid claims of validated criticality from œÉ_proxy.
./docs/COMPONENT_AUDIT.md:14:| P2-10 | P2-10 | VERIFIED | src/bnsyn/calibration/fit.py | tests/test_calibration_smoke.py; tests/validation/test_calibration_validation.py | CLM-0024 | Deterministic least-squares fit validated. |
./docs/appendix/EXECUTIVE_SUMMARY.md:15:- ‚úÖ **Formal specification:** 12-component SPEC with equations + calibration + failure envelopes
./docs/VCG.md:27:- Define effort proxy (optional, non-normative): `cost_i(t)` (e.g., CPU seconds, tokens, wall-time).
./docs/CONSTITUTIONAL_AUDIT.md:20:## Criticality: proxy vs measurement
./docs/CONSTITUTIONAL_AUDIT.md:21:- Runtime control uses a **œÉ proxy** (fast, biased, for control).
./calibration_pack/prompts/calibration_contract_v2026_02.md:5:1. The agent SHALL emit all mandatory artifacts: `CALIBRATION_REPORT.json`, `CALIBRATION_SUMMARY.md`, and `calibration_pack/` subtrees.
./calibration_pack/prompts/calibration_contract_v2026_02.md:7:3. Outputs SHALL validate against JSON schemas in `calibration_pack/schemas/`.
./docs/_inventory.md:10:- calibration_pack
./docs/EVIDENCE_COVERAGE.md:20:| CLM-0024 | Tier-A | true | PROVEN | bjorck1996least | 10.1137/1.9781611971484 | P2-10 Calibration utilities | `src/bnsyn/calibration/fit.py` | `tests/test_calibration_smoke.py`, `tests/validation/test_calibration_validation.py` |
./docs/SPEC.md:4:It is structured as **12 components** with: (a) equations, (b) calibration knobs, (c) failure envelopes,
./docs/SPEC.md:27:| P2-10 | Calibration utilities (f‚ÄìI fit) | `bnsyn/calibration/fit.py` | `test_calibration_smoke.py` |
docs/benchmarks/SCHEMA.md:111:| `thermostat_exploration_mean` | - | Mean exploration proxy |
docs/HYPOTHESIS.md:32:### Synthetic Input Protocol
docs/math/MATH_SURFACES.md:7:- Component model surfaces explicitly defined by SPEC: AdEx neuron dynamics (P0-1), conductance synapses (P0-2), three-factor learning (P0-3), criticality control (P0-4), temperature gating (P1-5), consolidation (P1-6), energy regularization (P1-7), numerical methods (P2-8), determinism protocol (P2-9), calibration (P2-10), reference network simulator (P2-11), bench harness (P2-12).
docs/VCG.md:27:- Define effort proxy (optional, non-normative): `cost_i(t)` (e.g., CPU seconds, tokens, wall-time).
docs/CONSTITUTIONAL_AUDIT.md:20:## Criticality: proxy vs measurement
docs/CONSTITUTIONAL_AUDIT.md:21:- Runtime control uses a **œÉ proxy** (fast, biased, for control).
docs/_inventory.md:10:- calibration_pack
docs/CRITICALITY_CONTROL_VS_MEASUREMENT.md:3:## Runtime control (proxy)
docs/CRITICALITY_CONTROL_VS_MEASUREMENT.md:6:Example proxy:
docs/CRITICALITY_CONTROL_VS_MEASUREMENT.md:7:- œÉ_proxy(k) = A(k) / (A(k-1) + Œµ)
docs/CRITICALITY_CONTROL_VS_MEASUREMENT.md:10:- Label as **proxy** in code + docs.
docs/CRITICALITY_CONTROL_VS_MEASUREMENT.md:11:- Avoid claims of validated criticality from œÉ_proxy.
docs/EVIDENCE_COVERAGE.md:20:| CLM-0024 | Tier-A | true | PROVEN | bjorck1996least | 10.1137/1.9781611971484 | P2-10 Calibration utilities | `src/bnsyn/calibration/fit.py` | `tests/test_calibration_smoke.py`, `tests/validation/test_calibration_validation.py` |
docs/SPEC.md:4:It is structured as **12 components** with: (a) equations, (b) calibration knobs, (c) failure envelopes,
docs/SPEC.md:27:| P2-10 | Calibration utilities (f‚ÄìI fit) | `bnsyn/calibration/fit.py` | `test_calibration_smoke.py` |
docs/COMPONENT_AUDIT.md:14:| P2-10 | P2-10 | VERIFIED | src/bnsyn/calibration/fit.py | tests/test_calibration_smoke.py; tests/validation/test_calibration_validation.py | CLM-0024 | Deterministic least-squares fit validated. |
docs/appendix/EXECUTIVE_SUMMARY.md:15:- ‚úÖ **Formal specification:** 12-component SPEC with equations + calibration + failure envelopes
$ sed -n "1,260p" .github/workflows/ci-pr-atomic.yml
name: ci-pr-atomic

on:
  pull_request:
    types: [opened, synchronize, reopened, labeled, unlabeled, edited]
  push:
    branches: [main]
  workflow_dispatch:
    inputs:
      python-version:
        type: string
        default: "3.11"
      upload-codecov:
        type: boolean
        default: true
  workflow_call:
    inputs:
      python-version:
        type: string
        default: "3.11"
      upload-codecov:
        type: boolean
        default: true
    secrets:
      CODECOV_TOKEN:
        required: false

permissions:
  contents: read

concurrency:
  group: ci-pr-atomic-${{ github.ref }}
  cancel-in-progress: true

env:
  PIP_CACHE_DIR: ~/.cache/pip
  PYTHONHASHSEED: 0
  PYTHONDONTWRITEBYTECODE: 1
  PIP_DISABLE_PIP_VERSION_CHECK: 1
  PIP_NO_PYTHON_VERSION_WARNING: 1

jobs:
  changes:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: read
    outputs:
      code: ${{ steps.filter.outputs.code }}
      validation: ${{ steps.filter.outputs.validation }}
      property: ${{ steps.filter.outputs.property }}
      docs: ${{ steps.filter.outputs.docs }}
      dependency_manifest: ${{ steps.filter.outputs.dependency_manifest }}
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      - uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36
        id: filter
        with:
          filters: |
            code:
              - 'src/**'
              - 'tests/**'
            validation:
              - 'src/**'
              - 'tools/**'
              - 'scripts/**'
              - 'docs/**'
              - 'tests/**'
            property:
              - 'src/**'
              - 'tests/**'
            docs:
              - 'docs/**'
              - 'README*'
              - 'mkdocs.yml'
              - 'pyproject.toml'
            dependency_manifest:
              - 'pyproject.toml'
              - 'requirements*.txt'

  gate-profile:
    permissions:
      contents: read
    uses: ./.github/workflows/_reusable_gate_profile.yml
    with:
      profile: pr

  determinism:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      - uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ inputs['python-version'] || '3.11' }}
          cache: "pip"
          cache-dependency-path: |
            pyproject.toml
            requirements-lock.txt
      - name: Pin pip
        uses: ./.github/actions/pin-pip
      - name: Log pip version
        run: python -m pip --version
      - run: python -m pip install -e ".[dev,test]"
      - name: Test determinism (run 1)
        id: run1
        run: pytest tests/test_determinism.py tests/properties/test_properties_determinism.py -v --tb=short
      - name: Test determinism (run 2)
        id: run2
        run: pytest tests/test_determinism.py tests/properties/test_properties_determinism.py -v --tb=short
      - name: Test determinism (run 3)
        id: run3
        run: pytest tests/test_determinism.py tests/properties/test_properties_determinism.py -v --tb=short
      - name: Check RNG isolation
        id: rng
        run: pytest tests/test_determinism.py::test_no_global_numpy_rng_usage -v
      - name: Generate summary
        if: always()
        run: |
          summary_file="$GITHUB_STEP_SUMMARY"
          {
            echo "##  Determinism Verification (3x Runs)"
            echo ""
            echo "| Run | Status | Result |"
            echo "|-----|--------|--------|"
            if [ "${{ steps.run1.outcome }}" = "success" ]; then
              echo "| 1 |  PASS | Identical outputs |"
            else
              echo "| 1 |  FAIL | Non-deterministic |"
            fi
            if [ "${{ steps.run2.outcome }}" = "success" ]; then
              echo "| 2 |  PASS | Identical outputs |"
            else
              echo "| 2 |  FAIL | Non-deterministic |"
            fi
            if [ "${{ steps.run3.outcome }}" = "success" ]; then
              echo "| 3 |  PASS | Identical outputs |"
            else
              echo "| 3 |  FAIL | Non-deterministic |"
            fi
            echo ""
            echo "| Check | Status |"
            echo "|-------|--------|"
            if [ "${{ steps.rng.outcome }}" = "success" ]; then
              echo "| RNG Isolation |  PASS |"
            else
              echo "| RNG Isolation |  FAIL |"
            fi
            echo ""
            if [ "${{ steps.run1.outcome }}" = "success" ] && [ "${{ steps.run2.outcome }}" = "success" ] && [ "${{ steps.run3.outcome }}" = "success" ]; then
              echo "** All runs produced identical outputs (A1: Determinism 96%)**"
            else
              echo "** Determinism check failed**"
            fi
          } >> "$summary_file"


  contracts:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    timeout-minutes: 12
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      - uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ inputs['python-version'] || '3.11' }}
          cache: "pip"
      - name: Pin pip
        uses: ./.github/actions/pin-pip
      - name: Log pip version
        run: python -m pip --version
      - run: python -m pip install -e ".[test]"
      - name: Validate traceability table
        run: python -m scripts.validate_traceability
      - name: Check internal docs links
        run: python -m scripts.check_internal_links
      - name: Run no-escape contract tests
        run: |
          pytest -q             tests/test_actions_pinning.py             tests/test_no_escape_tripwires.py             tests/test_schema_contracts.py             tests/test_verify_reproducible_artifacts.py
      - name: Verify reproducible generated artifacts
        run: |
          python -m scripts.verify_reproducible_artifacts             --spec evidence/zqsg_2026_02_12/repro_spec.json             --runs 3             --report evidence/zqsg_2026_02_12/repro_report_ci.json
      - name: Upload contract artifacts
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: no-escape-contracts-${{ github.sha }}
          path: |
            evidence/zqsg_2026_02_12/repro_report_ci.json
          if-no-files-found: error
          retention-days: 30

  quality:
    permissions:
      contents: read
    uses: ./.github/workflows/_reusable_quality.yml
    with:
      python-version: ${{ inputs['python-version'] || '3.11' }}
      mypy-strict: true
      pylint-threshold: 7.5

  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      - uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ inputs['python-version'] || '3.11' }}
          cache: "pip"
          cache-dependency-path: |
            pyproject.toml
            requirements-lock.txt
      - name: Pin pip
        uses: ./.github/actions/pin-pip
      - name: Log pip version
        run: python -m pip --version
      - run: python -m pip install -e ".[dev,test]" build
      - name: Verify lockfile freshness
        run: |
          python -m pip install pip-tools
          PYENV_VERSION=3.11.14 pip-compile --extra=dev --generate-hashes --output-file=requirements-lock.txt pyproject.toml
          git diff --exit-code -- requirements-lock.txt
      - run: python -m build
      - name: Install from wheel in clean venv
        run: |
          python -m venv .venv-wheel
          . .venv-wheel/bin/activate
          python -m pip install --upgrade pip
          python -m pip install dist/*.whl
          python -c "import bnsyn; print(bnsyn.__version__)"

  smoke-wheel-matrix:
    name: smoke-wheel-matrix (py${{ matrix.python-version }})
    runs-on: ubuntu-latest
    permissions:
      contents: read
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.11", "3.12"]
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      - uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ matrix.python-version }}
          cache: "pip"
      - name: Pin pip
        uses: ./.github/actions/pin-pip
      - name: Log pip version
        run: python -m pip --version
      - run: python -m pip install -e ".[dev,test]" build
      - name: Smoke tests
        run: pytest -m smoke -v --tb=short
$ sed -n "1,220p" README.md
<div align="center">
  <img src="docs/assets/hero.svg" alt="BN-Syn project banner" width="100%" />
</div>

# BN-Syn Thermostated Bio-AI System

BN-Syn is a repository for phase-controlled emergent dynamics simulations implemented in `src/bnsyn/` (see path/src/bnsyn).
The repository includes SSOT and governance assets under `specs/`, `schemas/`, `claims/`, `scripts/`, and `docs/` (see path/specs) (see path/schemas) (see path/claims) (see path/scripts) (see path/docs).

[![CI PR](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/ci-pr.yml/badge.svg)](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/ci-pr.yml)
[![CI Validation](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/ci-validation.yml/badge.svg)](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/ci-validation.yml)
[![Atomic PR Gate](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/ci-pr-atomic.yml/badge.svg)](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/ci-pr-atomic.yml)
[![Docs](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/docs.yml/badge.svg)](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/docs.yml)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-%3E%3D3.11-3776AB.svg)](pyproject.toml)

## What‚Äôs in this repo

- CLI entrypoint: `src/bnsyn/cli.py` (see path/src/bnsyn/cli.py)
- Runtime package: `src/bnsyn/` (see path/src/bnsyn)
- Experiment inputs: `experiments/` (see path/experiments)
- Artifact outputs: `results/` and `figures/` (see path/results) (see path/figures)
- Validation scripts: `scripts/` (see path/scripts)
- CI workflows: `.github/workflows/` (see path/.github/workflows)

## Quickstart (‚âà60s)

```bash
make quickstart-smoke
```

```bash
python -m pip install -e .
python -m bnsyn --help
bnsyn demo --steps 120 --dt-ms 0.1 --seed 123 --N 32
```

```bash
python tools/generate_inventory.py --check
python -m scripts.check_internal_links
python -m scripts.check_quickstart_consistency
```

## Architecture at a glance

```mermaid
flowchart LR
  A["src/bnsyn/cli.py"] --> B["src/bnsyn/"]
  B --> C["experiments/"]
  C --> D["results/ + figures/"]
  E["specs/ + schemas/ + claims/ + docs/"] --> F["scripts/"]
  F --> G[".github/workflows/"]
```

### Key Paths

- CLI: `src/bnsyn/cli.py` (see path/src/bnsyn/cli.py)
- Runtime: `src/bnsyn/` (see path/src/bnsyn)
- Experiments: `experiments/` (see path/experiments)
- Artifacts: `results/`, `figures/` (see path/results) (see path/figures)
- SSOT: `specs/`, `schemas/`, `claims/`, `docs/` (see path/specs) (see path/schemas) (see path/claims) (see path/docs)
- Validation: `scripts/` (see path/scripts)
- CI: `.github/workflows/` (see path/.github/workflows)

## Status

This project is research-grade / pre-production. No battle usage claimed.

- Maturity: research-grade / pre-production (see path/docs/STATUS.md)
- Missing layers:
  - SRE runbooks under SLA
  - external integration contracts
  - stabilized public API/semver as product
  - perf budgets as ‚Äúmust‚Äù [NORMATIVE][CLM-0011]
  - support/release cadence as product

## Docs hub

- [Documentation index](docs/INDEX.md) (see path/docs/INDEX.md)
$ test -f docs/TESTING.md && sed -n "1,240p" docs/TESTING.md || true
# Testing & Coverage (Canonical)

This document is the **single source of truth** for running tests and coverage in this repository.

## Install test dependencies

```bash
python -m pip install -e ".[test]"
```

Expected output pattern:
- `Successfully installed bnsyn-...`
- No import errors for `pytest`, `pytest-cov`, `hypothesis`.

## Run default test suite

```bash
make test
```

Equivalent explicit command:

```bash
python -m pytest -m "not validation" -q
```

Expected output pattern:
- Dots for passing tests.
- Final summary with `passed` and optional `skipped`.

## Run smoke marker tests

```bash
python -m pytest -m smoke -q
```

Expected output pattern:
- Only smoke-marked tests.


## Property test contour (Hypothesis)

Hypothesis profiles are defined only in:
- `tests/properties/conftest.py`

Run property tests (requires `hypothesis` installed):

```bash
HYPOTHESIS_PROFILE=ci python -m pytest tests/properties -m property -q
```

Alternate profiles:

```bash
HYPOTHESIS_PROFILE=quick python -m pytest tests/properties -m property -q
HYPOTHESIS_PROFILE=thorough python -m pytest tests/properties -m property -q
```

Run non-property tests without Hypothesis dependency:

```bash
python -m pytest -m "not property" -q
```

Behavior when `hypothesis` is missing:
- `python -m pytest -m "not property" -q` succeeds.
- `python -m pytest tests/properties -m property -q` fails with explicit `ModuleNotFoundError: No module named 'hypothesis'`.

## Generate fast local coverage artifacts (canonical dev path)

```bash
make coverage-fast
```

Equivalent explicit command:

```bash
python -m pytest -m "not (validation or property)" --cov=bnsyn --cov-report=term-missing --cov-report=xml:coverage.xml -q
```

Artifacts:
- Terminal report with missing lines by module (`term-missing`).
- `coverage.xml` at repository root.

## Generate coverage artifacts

```bash
make coverage
```

Equivalent explicit command:

```bash
python -m pytest --cov=bnsyn --cov-report=term-missing:skip-covered --cov-report=xml:coverage.xml -q
```

Artifacts:
- Terminal report with missing lines by module.
- `coverage.xml` at repository root.

## Generate / refresh coverage baseline

```bash
make coverage-baseline
```

Equivalent explicit command:

```bash
python -m scripts.generate_coverage_baseline --coverage-xml coverage.xml --output quality/coverage_gate.json --minimum-percent 99.0
```

This baseline uses the same metric enforced by the gate: `coverage.xml line-rate`.

## Enforce coverage gate

```bash
make coverage-gate
```

Gate behavior:
- Fails if current coverage drops below baseline in `quality/coverage_gate.json`.
- Fails if current coverage drops below minimum floor in `quality/coverage_gate.json`.


## API contract check (canonical)

```bash
make api-contract
```

Equivalent explicit command:

```bash
python -m scripts.check_api_contract --baseline quality/api_contract_baseline.json
```

Expected output pattern:
- `API contract check passed`

## CI parity checks (local)

Use the same checks enforced in PR CI:

```bash
python -m pytest -q
python -m pytest --cov=bnsyn --cov-report=term-missing:skip-covered --cov-report=xml:coverage.xml -q
ruff check .
```

If a tool is unavailable locally, install via:

```bash
python -m pip install -e ".[test]"
```

Deferred gate note:
- `mypy` is configured in CI quality workflow; run locally only after full `.[dev]` install.


## Offline dependency workflow (Python 3.11)

Notes:
- `wheelhouse/` is platform-specific (implementation/ABI/platform tag). Build and validate for the same target.
- `wheelhouse-build` requires internet access. `wheelhouse-validate` and `dev-env-offline` are offline.
- `wheelhouse-build` uses `pip download --only-binary=:all: --no-deps`; lock file must stay fully pinned.
- `wheelhouse-validate` writes `artifacts/wheelhouse_report.json` by default.

Build the local wheelhouse from pinned lock dependencies:

```bash
make wheelhouse-build
```

Validate that every pinned dependency in `requirements-lock.txt` has a matching wheel in `wheelhouse/`:

```bash
make wheelhouse-validate
make wheelhouse-report
```

Install the development environment fully offline from the local wheelhouse:

```bash
make dev-env-offline
```

Equivalent install commands:

```bash
python -m pip install --no-index --find-links wheelhouse -r requirements-lock.txt
python -m pip install --no-index --find-links wheelhouse --no-deps -e .
```

Failure modes:
- Locked package has no wheel for the configured target tuple.
- Marker applicability differs from the target environment.
- Wheelhouse built for a different platform/ABI than the install target.

Validation exit codes:
- `0`: wheelhouse fully covers applicable locked requirements.
- `1`: one or more applicable locked requirements are missing wheels.
- `2`: lock contains unsupported or duplicate applicable requirement entries.

Report contains additional diagnostics:
- `duplicate_requirements`
- `incompatible_wheels`
- `malformed_wheels`

## Updating lock and wheelhouse

1. Refresh lock file after dependency changes:

```bash
pip-compile --extra=dev --generate-hashes --output-file=requirements-lock.txt pyproject.toml
```

2. Rebuild wheels for Python 3.11 and re-run validation:

```bash
make wheelhouse-build
make wheelhouse-validate
```
