timestamp_utc: 2026-02-16T12:32:50Z
cmd: sed -n "1,220p" README.md
exit: 0
stdout:
# BN-Syn Thermostated Bio-AI System

BN-Syn is the deterministic reference implementation of the BN-Syn Thermostated Bio-AI System defined by the specification and governance artifacts in this repository.

[![ci-pr](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/ci-pr.yml/badge.svg?branch=main)](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/ci-pr.yml)
[![ci-validation](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/ci-validation.yml/badge.svg?branch=main)](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/ci-validation.yml)
[![codeql](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/codeql.yml/badge.svg?branch=main)](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/codeql.yml)
[![codecov](https://codecov.io/gh/neuron7x/bnsyn-phase-controlled-emergent-dynamics/branch/main/graph/badge.svg?token=CODECOV_TOKEN)](https://codecov.io/gh/neuron7x/bnsyn-phase-controlled-emergent-dynamics)
[![ci-pr-atomic](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/ci-pr-atomic.yml/badge.svg?branch=main)](https://github.com/neuron7x/bnsyn-phase-controlled-emergent-dynamics/actions/workflows/ci-pr-atomic.yml)

BN-Syn is a deterministic, research-grade Bio-AI system that formalizes phase-controlled emergent dynamics with strict evidence and governance controls. This repository is the *single source of truth* for specifications, experiments, validation, and compliance artifacts.

## Start Here (Canonical Onboarding)

BN-Syn is a deterministic research/validation platform for phase-controlled emergent dynamics. The repository scope includes runtime simulation, contracts, verification scripts, and governance evidence artifacts. Non-goals: product UI, distributed serving infrastructure, and non-deterministic experimentation workflows.

- Repository map: [`docs/repo_map.md`](docs/repo_map.md)
- Usage workflows: [`docs/usage_workflows.md`](docs/usage_workflows.md)
- Scripts index: [`docs/scripts/index.md`](docs/scripts/index.md)
- Contracts docs: [`docs/contracts/index.md`](docs/contracts/index.md)
- Merge-readiness audit: [`docs/audit_merge_readiness.md`](docs/audit_merge_readiness.md)
- API reference: [`docs/api/index.md`](docs/api/index.md)

Canonical local commands:

```bash
python -m pip install -e ".[dev]"
python -m bnsyn.cli --help
python -m pytest tests -q
python -m scripts.check_quickstart_consistency
make docs
```

## Contents

- [Quality Assurance](#quality-assurance)
- [Project Status](#project-status)
- [Validation & Testing Strategy](#validation--testing-strategy)
- [Results: Temperature-Controlled Consolidation](#results-temperature-controlled-consolidation)
- [Sleepâ€“Emergence Stack](#sleepemergence-stack)
- [Interactive Demo](#-interactive-demo)
- [Start Here](#start-here)
- [Repository Contract](#repository-contract)
- [Quickstart](#quickstart)
- [Codebase Readiness](#codebase-readiness)
- [Demo Runbook](#demo-runbook)
- [Release Notes](#release-notes)
- [Development Workflow](#development-workflow)
- [CI on Pull Requests](#ci-on-pull-requests)
- [Architecture at a Glance](#architecture-at-a-glance)
- [Evidence & Bibliography](#evidence--bibliography)
- [How to Cite](#how-to-cite)
- [License / Security / Contributing](#license--security--contributing)

## Quality Assurance

Quality gates are command-verifiable and documented in one place:

- Canonical local test/coverage commands: [`docs/TESTING.md`](docs/TESTING.md)
- CI gate definitions: [`docs/CI_GATES.md`](docs/CI_GATES.md)
- Workflow contracts: [`.github/WORKFLOW_CONTRACTS.md`](.github/WORKFLOW_CONTRACTS.md)
- Evidence mapping: [`docs/EVIDENCE_COVERAGE.md`](docs/EVIDENCE_COVERAGE.md)

No aggregate quality percentages are published in README; only reproducible command outputs and artifacts are considered normative.

---

## Project Status

Official status declaration: [`docs/STATUS.md`](docs/STATUS.md).

## Validation & Testing Strategy

Canonical commands for install, test, coverage, and coverage gate live in [`docs/TESTING.md`](docs/TESTING.md).

BN-Syn implements a **3-tier test selection strategy** for optimal coverage without blocking development:

### Tier 1: BLOCKING (PR Gates) âš¡
**Every PR, ~8 min** â€” Fast smoke tests, SSOT validation, claims coverage enforcement (CLM-0011), security scans

### Tier 2: NON-BLOCKING Validation ðŸ”¬
**Daily 2 AM UTC** â€” 10 scientific validation tests + 8 property-based invariants (Hypothesis)

### Tier 3: Performance Tracking ðŸ“Š
**Weekly Sunday 3 AM UTC** â€” Benchmark regression detection against golden baseline

**Learn More:**
- [CI Gates](docs/CI_GATES.md) â€” Test selection strategy
- [Test Protocol](docs/ACTIONS_TEST_PROTOCOL.md) â€” GitHub Actions testing guide
- [Evidence Coverage](docs/EVIDENCE_COVERAGE.md) â€” Claimsâ†’Evidence traceability

---

## Results: Temperature-Controlled Consolidation

BN-Syn demonstrates **phase-controlled emergent dynamics** through temperature-gated synaptic consolidation. Our flagship experiment (v2) validates that piecewise cooling schedules improve consolidation stability while maintaining active protein synthesis and consolidation, demonstrating stability gains without trivially suppressing plasticity.

### Key Findings (v2: Piecewise Cooling with Non-Trivial Consolidation)

| Condition | w_cons Variance | w_total Variance | Protein Level | Reduction vs Fixed-High |
|-----------|-----------------|------------------|---------------|-------------------------|
| **cooling_piecewise** | 0.003039 | 0.010302 | 0.9999 | **18.77%** âœ“ |
| fixed_high | 0.003600 | 0.012683 | 0.9999 | baseline |
| fixed_low | 0.000000 | 0.000000 | 0.0002 | â€” |
| random_T | 0.004736 | 0.016460 | 0.9999 | worse |

**Hypothesis H1 SUPPORTED**: Piecewise cooling reduces w_total stability variance by **18.77%** while maintaining active consolidation (protein=0.9999, |w_cons|=0.0012), exceeding the â‰¥10% target without trivially disabling plasticity.

**v1 showed extreme variance reduction (99.996%) but achieved this by suppressing consolidation; v2 demonstrates stability gains with protein synthesis active.**

### Visualizations

![Stability Comparison](figures/temp_ablation_v2/hero.png)

*Stability variance across temperature conditions (20 seeds). Lower variance indicates more reproducible consolidation.*

![Comparison Grid](figures/temp_ablation_v2/comparison_grid.png)

*Multi-panel view: temperature profiles, weight dynamics, protein synthesis, and stability metrics.*

### Reproduce the Flagship Experiment

```bash
# Install with visualization dependencies
pip install -e ".[dev,viz]"

# Run full validation experiment v2 (20 seeds, ~2-3 minutes)
python -m experiments.runner temp_ablation_v2

# Generate visualizations
python -m scripts.visualize_experiment --run-id temp_ablation_v2

# Verify hypothesis
python -m experiments.verify_hypothesis docs/HYPOTHESIS.md results/temp_ablation_v2
```

**Fast smoke test** (5 seeds):
```bash
python -m experiments.runner temp_ablation_v2 --seeds 5 --out results/_smoke
```

**Baseline v1 experiment** (extreme variance reduction but suppresses consolidation):
```bash
python -m experiments.runner temp_ablation_v1
```

See [`docs/HYPOTHESIS.md`](docs/HYPOTHESIS.md) for experimental design and acceptance criteria.

---

## Sleepâ€“Emergence Stack

BN-Syn now includes a **Sleepâ€“Emergence Stack** that integrates sleep-wake cycles, memory consolidation, attractor crystallization, and phase transition tracking. This provides a cohesive framework for studying emergent dynamics with deterministic guarantees.

### Quick Demo

Run the end-to-end sleep-stack demo:

```bash
bnsyn sleep-stack --seed 123 --steps-wake 800 --steps-sleep 600 --out results/demo1
```

**Outputs:**
- `results/demo1/manifest.json`: Reproducibility metadata (seed, params, git SHA)
- `results/demo1/metrics.json`: Metrics (phase transitions, attractors, consolidation stats)
- `figures/demo1/summary.png`: Summary figure (if matplotlib installed)

**Expected runtime:** ~5-10 seconds

**Scaled flagship run (N=2000, extended wake/sleep):**

```bash
python -m bnsyn.tools.run_scaled_sleep_stack \
  --out artifacts/local_runs/scaled_sleep_stack_n2000 \
  --seed 123 --n 2000 --steps-wake 2400 --steps-sleep 1800
```

**Optional scale benchmark:**

```bash
python -m bnsyn.tools.benchmark_sleep_stack_scale
```

For CI/quick smoke runs, use fast flags to reduce workload:

```bash
python -m bnsyn.tools.run_scaled_sleep_stack \
  --out /tmp/bnsyn_scaled_smoke \
  --seed 42 --n 80 --steps-wake 30 --steps-sleep 30 \
  --baseline-steps-wake 20 --baseline-steps-sleep 10 \
  --determinism-runs 1 --skip-backend-equivalence --skip-baseline \
  --no-raster --no-plots
```

The generated `<out>/metrics.json` contains fields:
- `seed`, `N_scaled`, `steps_wake_scaled`, `steps_sleep_scaled`
- `determinism_hashes` (per-run manifest/metrics hashes)
- `determinism_runs` (int) and `determinism_identical` (bool or null when runs < 2)
- `backend_equivalence` (`atol`, `equivalent`, `max_abs_sigma_diff`, `skipped`; values may be null when skipped)
- `baseline_skipped` (bool) and `baseline` (`wake_std_sigma`, `transitions`, `attractors` or null when baseline skipped)
- `scaled` (`wake_std_sigma`, `transitions`, `attractors`, `crystallization_progress`)
- `benchmark` (`elapsed_s`, `memory_current_bytes`, `memory_peak_bytes`)

Benchmark output is written to `artifacts/local_runs/benchmarks_scale/metrics.json` and is machine-dependent.

### Minimal Usage Example

```python
from bnsyn.rng import seed_all
from bnsyn.sim.network import Network, NetworkParams
from bnsyn.config import AdExParams, SynapseParams, CriticalityParams, TemperatureParams
from bnsyn.temperature.schedule import TemperatureSchedule
from bnsyn.sleep import SleepCycle, default_human_sleep_cycle
from bnsyn.memory import MemoryConsolidator
from bnsyn.criticality import PhaseTransitionDetector
from bnsyn.emergence import AttractorCrystallizer

# Initialize with deterministic seed
pack = seed_all(42)
net = Network(NetworkParams(N=64), AdExParams(), SynapseParams(), 
stderr:
---
timestamp_utc: 2026-02-16T12:32:53Z
cmd: sed -n "1,240p" docs/usage_workflows.md
exit: 0
stdout:
# Usage Workflows

## Purpose
Golden-path operational workflows with exact commands, expected artifacts, and troubleshooting notes.

## 1) Environment setup

```bash
python -m pip install -e ".[dev]"
```

Expected outcome:
- `bnsyn` console script available.
- Sphinx + pytest tooling installed.

Troubleshooting:
- If dependency resolution fails, retry with upgraded pip: `python -m pip install --upgrade pip`.

## 2) Validate mathematical/contracts behavior

```bash
python -m pytest tests -q
```

Expected outcome:
- Exit code `0` and pytest summary.

Troubleshooting:
- If tests fail on environment-specific optional dependencies, run targeted subsets from `docs/TESTING.md`.

## 3) Run core flows

CLI discovery:
```bash
python -m bnsyn.cli --help
```

Sleep-stack example:
```bash
bnsyn sleep-stack --seed 123 --steps-wake 800 --steps-sleep 600 --out results/demo1
```

Expected artifacts:
- `results/demo1/manifest.json`
- `results/demo1/metrics.json`
- `figures/demo1/summary.png` (if plotting dependencies installed)

## 4) Generate benchmark / analysis artifacts

```bash
python -m scripts.run_benchmarks --help
python -m scripts.compare_benchmarks --help
```

Expected outcome:
- Command-specific benchmark artifacts in `benchmarks/` (see per-script pages in `docs/scripts/`).

Troubleshooting:
- If a script exits non-zero, inspect its page under `docs/scripts/` for failure modes and side effects.

## 5) Build documentation

```bash
make docs
```

Expected outcome:
- HTML output under `docs/_build/`.

Troubleshooting:
- If build fails with missing Sphinx deps, reinstall dev dependencies and retry.
- If autodoc import errors occur, ensure command is run from repository root.

## 6) Documentation verification checklist

```bash
python -m sphinx -b html docs docs/_build/html
python -m sphinx -b linkcheck docs docs/_build/linkcheck
```

Expected outputs:
- `docs/_build/html/index.html`
- `docs/_build/linkcheck/output.txt`


## 7) Repository inventory consistency

```bash
python tools/generate_inventory.py --check
```

If this fails, regenerate and stage inventory:

```bash
python tools/generate_inventory.py
git add INVENTORY.json
```
stderr:
---
timestamp_utc: 2026-02-16T12:32:53Z
cmd: sed -n "1,220p" docs/QUICKSTART.md
exit: 0
stdout:
# Deterministic Quickstart Contract

This quickstart is a runnable contract:

1. install
2. verify CLI
3. run minimal deterministic simulation
4. verify expected output shape

## Install

```bash
python -m pip install -e .
```

## Verify CLI

```bash
python -m bnsyn --help
```

## Run minimal deterministic simulation

```bash
bnsyn demo --steps 120 --dt-ms 0.1 --seed 123 --N 32
```

## Expected output contract

Top-level JSON object with field `demo` and deterministic metric keys:

- `demo.sigma_mean`
- `demo.sigma_std`
- `demo.rate_mean_hz`
- `demo.rate_std`

Expected value ranges:

- `0.0 <= demo.sigma_mean <= 5.0`
- `0.0 <= demo.rate_mean_hz <= 1000.0`
stderr:
---
timestamp_utc: 2026-02-16T12:32:54Z
cmd: sed -n "1,220p" docs/TESTING.md
exit: 0
stdout:
# Testing & Coverage (Canonical)

This document is the **single source of truth** for running tests and coverage in this repository.

## Install test dependencies

```bash
python -m pip install -e ".[test]"
```

Expected output pattern:
- `Successfully installed bnsyn-...`
- No import errors for `pytest`, `pytest-cov`, `hypothesis`.

## Run default test suite

```bash
make test
```

Equivalent explicit command:

```bash
python -m pytest -m "not validation" -q
```

Expected output pattern:
- Dots for passing tests.
- Final summary with `passed` and optional `skipped`.

## Run smoke marker tests

```bash
python -m pytest -m smoke -q
```

Expected output pattern:
- Only smoke-marked tests.


## Property test contour (Hypothesis)

Hypothesis profiles are defined only in:
- `tests/properties/conftest.py`

Run property tests (requires `hypothesis` installed):

```bash
HYPOTHESIS_PROFILE=ci python -m pytest tests/properties -m property -q
```

Alternate profiles:

```bash
HYPOTHESIS_PROFILE=quick python -m pytest tests/properties -m property -q
HYPOTHESIS_PROFILE=thorough python -m pytest tests/properties -m property -q
```

Run non-property tests without Hypothesis dependency:

```bash
python -m pytest -m "not property" -q
```

Behavior when `hypothesis` is missing:
- `python -m pytest -m "not property" -q` succeeds.
- `python -m pytest tests/properties -m property -q` fails with explicit `ModuleNotFoundError: No module named 'hypothesis'`.

## Generate fast local coverage artifacts (canonical dev path)

```bash
make coverage-fast
```

Equivalent explicit command:

```bash
python -m pytest -m "not (validation or property)" --cov=bnsyn --cov-report=term-missing --cov-report=xml:coverage.xml -q
```

Artifacts:
- Terminal report with missing lines by module (`term-missing`).
- `coverage.xml` at repository root.

## Generate coverage artifacts

```bash
make coverage
```

Equivalent explicit command:

```bash
python -m pytest --cov=bnsyn --cov-report=term-missing:skip-covered --cov-report=xml:coverage.xml -q
```

Artifacts:
- Terminal report with missing lines by module.
- `coverage.xml` at repository root.

## Generate / refresh coverage baseline

```bash
make coverage-baseline
```

Equivalent explicit command:

```bash
python -m scripts.generate_coverage_baseline --coverage-xml coverage.xml --output quality/coverage_gate.json --minimum-percent 99.0
```

This baseline uses the same metric enforced by the gate: `coverage.xml line-rate`.

## Enforce coverage gate

```bash
make coverage-gate
```

Gate behavior:
- Fails if current coverage drops below baseline in `quality/coverage_gate.json`.
- Fails if current coverage drops below minimum floor in `quality/coverage_gate.json`.


## API contract check (canonical)

```bash
make api-contract
```

Equivalent explicit command:

```bash
python -m scripts.check_api_contract --baseline quality/api_contract_baseline.json
```

Expected output pattern:
- `API contract check passed`

## CI parity checks (local)

Use the same checks enforced in PR CI:

```bash
python -m pytest -q
python -m pytest --cov=bnsyn --cov-report=term-missing:skip-covered --cov-report=xml:coverage.xml -q
ruff check .
```

If a tool is unavailable locally, install via:

```bash
python -m pip install -e ".[test]"
```

Deferred gate note:
- `mypy` is configured in CI quality workflow; run locally only after full `.[dev]` install.


## Offline dependency workflow (Python 3.11)

Notes:
- `wheelhouse/` is platform-specific (implementation/ABI/platform tag). Build and validate for the same target.
- `wheelhouse-build` requires internet access. `wheelhouse-validate` and `dev-env-offline` are offline.
- `wheelhouse-build` uses `pip download --only-binary=:all: --no-deps`; lock file must stay fully pinned.
- `wheelhouse-validate` writes `artifacts/wheelhouse_report.json` by default.

Build the local wheelhouse from pinned lock dependencies:

```bash
make wheelhouse-build
```

Validate that every pinned dependency in `requirements-lock.txt` has a matching wheel in `wheelhouse/`:

```bash
make wheelhouse-validate
make wheelhouse-report
```

Install the development environment fully offline from the local wheelhouse:

```bash
make dev-env-offline
```

Equivalent install commands:

```bash
python -m pip install --no-index --find-links wheelhouse -r requirements-lock.txt
python -m pip install --no-index --find-links wheelhouse --no-deps -e .
```

Failure modes:
- Locked package has no wheel for the configured target tuple.
- Marker applicability differs from the target environment.
- Wheelhouse built for a different platform/ABI than the install target.

Validation exit codes:
- `0`: wheelhouse fully covers applicable locked requirements.
- `1`: one or more applicable locked requirements are missing wheels.
- `2`: lock contains unsupported or duplicate applicable requirement entries.

Report contains additional diagnostics:
- `duplicate_requirements`
- `incompatible_wheels`
- `malformed_wheels`

## Updating lock and wheelhouse

1. Refresh lock file after dependency changes:

```bash
pip-compile --extra=dev --generate-hashes --output-file=requirements-lock.txt pyproject.toml
```

2. Rebuild wheels for Python 3.11 and re-run validation:

```bash
stderr:
---
timestamp_utc: 2026-02-16T12:32:57Z
cmd: sed -n "1,240p" .github/workflows/ci-pr-atomic.yml
exit: 0
stdout:
name: ci-pr-atomic

on:
  pull_request:
    types: [opened, synchronize, reopened, labeled, unlabeled, edited]
  push:
    branches: [main]
  workflow_dispatch:
    inputs:
      python-version:
        type: string
        default: "3.11"
      upload-codecov:
        type: boolean
        default: true
  workflow_call:
    inputs:
      python-version:
        type: string
        default: "3.11"
      upload-codecov:
        type: boolean
        default: true
    secrets:
      CODECOV_TOKEN:
        required: false

permissions:
  contents: read

concurrency:
  group: ci-pr-atomic-${{ github.ref }}
  cancel-in-progress: true

env:
  PIP_CACHE_DIR: ~/.cache/pip
  PYTHONHASHSEED: 0
  PYTHONDONTWRITEBYTECODE: 1
  PIP_DISABLE_PIP_VERSION_CHECK: 1
  PIP_NO_PYTHON_VERSION_WARNING: 1

jobs:
  changes:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: read
    outputs:
      code: ${{ steps.filter.outputs.code }}
      validation: ${{ steps.filter.outputs.validation }}
      property: ${{ steps.filter.outputs.property }}
      docs: ${{ steps.filter.outputs.docs }}
      dependency_manifest: ${{ steps.filter.outputs.dependency_manifest }}
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      - uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36
        id: filter
        with:
          filters: |
            code:
              - 'src/**'
              - 'tests/**'
            validation:
              - 'src/**'
              - 'tools/**'
              - 'scripts/**'
              - 'docs/**'
              - 'tests/**'
            property:
              - 'src/**'
              - 'tests/**'
            docs:
              - 'docs/**'
              - 'README*'
              - 'mkdocs.yml'
              - 'pyproject.toml'
            dependency_manifest:
              - 'pyproject.toml'
              - 'requirements*.txt'

  gate-profile:
    permissions:
      contents: read
    uses: ./.github/workflows/_reusable_gate_profile.yml
    with:
      profile: pr

  determinism:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      - uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ inputs['python-version'] || '3.11' }}
          cache: "pip"
          cache-dependency-path: |
            pyproject.toml
            requirements-lock.txt
      - name: Pin pip
        uses: ./.github/actions/pin-pip
      - name: Log pip version
        run: python -m pip --version
      - run: python -m pip install -e ".[dev,test]"
      - name: Test determinism (run 1)
        id: run1
        run: pytest tests/test_determinism.py tests/properties/test_properties_determinism.py -v --tb=short
      - name: Test determinism (run 2)
        id: run2
        run: pytest tests/test_determinism.py tests/properties/test_properties_determinism.py -v --tb=short
      - name: Test determinism (run 3)
        id: run3
        run: pytest tests/test_determinism.py tests/properties/test_properties_determinism.py -v --tb=short
      - name: Check RNG isolation
        id: rng
        run: pytest tests/test_determinism.py::test_no_global_numpy_rng_usage -v
      - name: Generate summary
        if: always()
        run: |
          summary_file="$GITHUB_STEP_SUMMARY"
          {
            echo "##  Determinism Verification (3x Runs)"
            echo ""
            echo "| Run | Status | Result |"
            echo "|-----|--------|--------|"
            if [ "${{ steps.run1.outcome }}" = "success" ]; then
              echo "| 1 |  PASS | Identical outputs |"
            else
              echo "| 1 |  FAIL | Non-deterministic |"
            fi
            if [ "${{ steps.run2.outcome }}" = "success" ]; then
              echo "| 2 |  PASS | Identical outputs |"
            else
              echo "| 2 |  FAIL | Non-deterministic |"
            fi
            if [ "${{ steps.run3.outcome }}" = "success" ]; then
              echo "| 3 |  PASS | Identical outputs |"
            else
              echo "| 3 |  FAIL | Non-deterministic |"
            fi
            echo ""
            echo "| Check | Status |"
            echo "|-------|--------|"
            if [ "${{ steps.rng.outcome }}" = "success" ]; then
              echo "| RNG Isolation |  PASS |"
            else
              echo "| RNG Isolation |  FAIL |"
            fi
            echo ""
            if [ "${{ steps.run1.outcome }}" = "success" ] && [ "${{ steps.run2.outcome }}" = "success" ] && [ "${{ steps.run3.outcome }}" = "success" ]; then
              echo "** All runs produced identical outputs (A1: Determinism 96%)**"
            else
              echo "** Determinism check failed**"
            fi
          } >> "$summary_file"


  contracts:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    timeout-minutes: 12
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      - uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ inputs['python-version'] || '3.11' }}
          cache: "pip"
      - name: Pin pip
        uses: ./.github/actions/pin-pip
      - name: Log pip version
        run: python -m pip --version
      - run: python -m pip install -e ".[test]"
      - name: Run no-escape contract tests
        run: |
          pytest -q             tests/test_actions_pinning.py             tests/test_no_escape_tripwires.py             tests/test_schema_contracts.py             tests/test_verify_reproducible_artifacts.py
      - name: Verify reproducible generated artifacts
        run: |
          python -m scripts.verify_reproducible_artifacts             --spec evidence/zqsg_2026_02_12/repro_spec.json             --runs 3             --report evidence/zqsg_2026_02_12/repro_report_ci.json
      - name: Upload contract artifacts
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: no-escape-contracts-${{ github.sha }}
          path: |
            evidence/zqsg_2026_02_12/repro_report_ci.json
          if-no-files-found: error
          retention-days: 30

  quality:
    permissions:
      contents: read
    uses: ./.github/workflows/_reusable_quality.yml
    with:
      python-version: ${{ inputs['python-version'] || '3.11' }}
      mypy-strict: true
      pylint-threshold: 7.5

  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      - uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ inputs['python-version'] || '3.11' }}
          cache: "pip"
          cache-dependency-path: |
            pyproject.toml
            requirements-lock.txt
      - name: Pin pip
        uses: ./.github/actions/pin-pip
      - name: Log pip version
        run: python -m pip --version
      - run: python -m pip install -e ".[dev,test]" build
      - name: Verify lockfile freshness
        run: |
          python -m pip install pip-tools
          PYENV_VERSION=3.11.14 pip-compile --extra=dev --generate-hashes --output-file=requirements-lock.txt pyproject.toml
          git diff --exit-code -- requirements-lock.txt
      - run: python -m build
      - name: Install from wheel in clean venv
        run: |
          python -m venv .venv-wheel
          . .venv-wheel/bin/activate
          python -m pip install --upgrade pip
          python -m pip install dist/*.whl
          python -c "import bnsyn; print(bnsyn.__version__)"

  smoke-wheel-matrix:
    name: smoke-wheel-matrix (py${{ matrix.python-version }})
    runs-on: ubuntu-latest
    permissions:
      contents: read
    timeout-minutes: 30
    strategy:
stderr:
---
timestamp_utc: 2026-02-16T12:32:58Z
cmd: sed -n "1,260p" .github/workflows/ci-pr.yml
exit: 0
stdout:
# REUSABLE NON-PR-GATE: long-running workflow_call; must not run on pull_request/push.
name: ci-pr

on:
  workflow_dispatch:
    inputs:
      python-version:
        type: string
        default: "3.11"
      upload-codecov:
        type: string
        default: "true"
  workflow_call:
    inputs:
      python-version:
        type: string
        default: "3.11"
      upload-codecov:
        type: string
        default: "true"
    secrets:
      CODECOV_TOKEN:
        required: false

permissions:
  contents: read

concurrency:
  group: ci-pr-${{ github.ref }}
  cancel-in-progress: true

jobs:
  ci-pr-atomic:
    uses: ./.github/workflows/ci-pr-atomic.yml
    with:
      python-version: ${{ inputs['python-version'] }}
      upload-codecov: ${{ fromJSON(inputs['upload-codecov']) }}
    secrets:
      CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
stderr:
---
timestamp_utc: 2026-02-16T12:33:00Z
cmd: sed -n "1,240p" .github/workflows/_reusable_quality.yml
exit: 0
stdout:
# REUSABLE NON-PR-GATE: long-running workflow_call; must not run on pull_request/push.
name: Reusable Quality Checks

on:
  workflow_call:
    inputs:
      python-version:
        description: 'Python version to use'
        type: string
        default: '3.11'
      mypy-strict:
        description: 'Enable mypy strict mode'
        type: boolean
        default: true
      pylint-threshold:
        description: 'Minimum pylint score (0.0-10.0)'
        type: number
        default: 7.5

permissions:
  contents: read

jobs:
  ruff:
    name: Ruff (Format + Lint)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      
      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ inputs['python-version'] }}
          cache: 'pip'
      
      - name: Pin pip
        uses: ./.github/actions/pin-pip

      - name: Log pip version
        run: python -m pip --version

      - name: Install dependencies
        run: python -m pip install -e ".[dev,test]"
      
      - name: Cache ruff
        uses: actions/cache@cdf6c1fa76f9f475f3d7449005a359c84ca0f306
        with:
          path: ~/.cache/ruff
          key: ruff-${{ runner.os }}-${{ hashFiles('pyproject.toml') }}
      
      - name: Ruff format check
        id: format
        run: |
          ruff format --check . 2>&1 | tee ruff-format.log
          echo "FORMAT_RESULT=$?" >> "$GITHUB_ENV"
      
      - name: Ruff lint
        id: lint
        run: |
          ruff check . 2>&1 | tee ruff-lint.log
          echo "LINT_RESULT=$?" >> "$GITHUB_ENV"
      
      - name: Generate summary
        if: always()
        run: |
          summary_file="$GITHUB_STEP_SUMMARY"
          {
            echo "##  Ruff Quality Check"
            echo ""
            echo "| Check | Status |"
            echo "|-------|--------|"
            if [ "${{ env.FORMAT_RESULT }}" = "0" ]; then
              echo "| Format |  PASS |"
            else
              echo "| Format |  FAIL |"
            fi
            if [ "${{ env.LINT_RESULT }}" = "0" ]; then
              echo "| Lint |  PASS |"
            else
              echo "| Lint |  FAIL |"
            fi
            echo ""
            echo "**Python Version:** ${{ inputs['python-version'] }}"
          } >> "$summary_file"
      
      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: ruff-logs-${{ github.sha }}
          path: |
            ruff-format.log
            ruff-lint.log
          if-no-files-found: ignore
          retention-days: 7
      
      - name: Fail if checks failed
        if: env.FORMAT_RESULT != '0' || env.LINT_RESULT != '0'
        run: exit 1

  mypy:
    name: Mypy (Type Checking)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      
      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ inputs['python-version'] }}
          cache: 'pip'
      
      - name: Pin pip
        uses: ./.github/actions/pin-pip

      - name: Log pip version
        run: python -m pip --version

      - name: Install dependencies
        run: python -m pip install -e ".[dev,test]"
      
      - name: Cache mypy
        uses: actions/cache@cdf6c1fa76f9f475f3d7449005a359c84ca0f306
        with:
          path: .mypy_cache
          key: mypy-${{ runner.os }}-${{ inputs['python-version'] }}-${{ hashFiles('src/**/*.py', 'pyproject.toml') }}
      
      - name: Mypy type check
        id: mypy
        run: |
          if [ "${{ inputs['mypy-strict'] }}" = "true" ]; then
            mypy src --strict --config-file pyproject.toml 2>&1 | tee mypy.log
          else
            mypy src --config-file pyproject.toml 2>&1 | tee mypy.log
          fi
          echo "MYPY_RESULT=$?" >> "$GITHUB_ENV"
      
      - name: Generate summary
        if: always()
        run: |
          summary_file="$GITHUB_STEP_SUMMARY"
          {
            echo "##  Mypy Type Check"
            echo ""
            if [ "${{ env.MYPY_RESULT }}" = "0" ]; then
              echo "| Status |  PASS |"
            else
              echo "| Status |  FAIL |"
            fi
            echo "|--------|---------|"
            echo "| Strict Mode | ${{ inputs['mypy-strict'] }} |"
            echo "| Python | ${{ inputs['python-version'] }} |"
            echo ""
            if [ -f mypy.log ]; then
              ERROR_COUNT=$(grep -c "error:" mypy.log || echo "0")
              echo "**Errors found:** $ERROR_COUNT"
            fi
          } >> "$summary_file"
      
      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: mypy-logs-${{ github.sha }}
          path: mypy.log
          if-no-files-found: ignore
          retention-days: 7
      
      - name: Fail if check failed
        if: env.MYPY_RESULT != '0'
        run: exit 1

  pylint:
    name: Pylint (Code Quality)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      
      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ inputs['python-version'] }}
          cache: 'pip'
      
      - name: Pin pip
        uses: ./.github/actions/pin-pip

      - name: Log pip version
        run: python -m pip --version

      - name: Install dependencies
        run: python -m pip install -e ".[dev,test]"
      
      - name: Pylint check
        id: pylint
        run: |
          pylint src/bnsyn --rcfile=pyproject.toml --fail-under="${{ inputs['pylint-threshold'] }}" 2>&1 | tee pylint.log
          echo "PYLINT_RESULT=$?" >> "$GITHUB_ENV"
      
      - name: Generate summary
        if: always()
        run: |
          summary_file="$GITHUB_STEP_SUMMARY"
          {
            echo "##  Pylint Code Quality"
            echo ""
            if [ "${{ env.PYLINT_RESULT }}" = "0" ]; then
              echo "| Status |  PASS |"
            else
              echo "| Status |  FAIL |"
            fi
            echo "|--------|---------|"
            echo "| Threshold | ${{ inputs['pylint-threshold'] }}/10.0 |"
            echo "| Python | ${{ inputs['python-version'] }} |"
            echo ""
            if [ -f pylint.log ]; then
              SCORE=$(grep "Your code has been rated at" pylint.log | sed 's/.*rated at \([0-9.]*\).*/\1/' || echo "N/A")
              echo "**Score:** $SCORE/10.0"
            fi
          } >> "$summary_file"
      
      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: pylint-logs-${{ github.sha }}
          path: pylint.log
          if-no-files-found: ignore
          retention-days: 7
      
      - name: Fail if check failed
        if: env.PYLINT_RESULT != '0'
        run: exit 1
stderr:
---
timestamp_utc: 2026-02-16T12:33:01Z
cmd: sed -n "1,220p" Makefile
exit: 0
stdout:
.PHONY: dev-setup quickstart-smoke dev-env-offline wheelhouse-build wheelhouse-validate wheelhouse-report wheelhouse-clean check test test-determinism test-validation coverage coverage-fast coverage-baseline coverage-gate quality format fix lint mypy ssot security clean docs validate-claims-coverage docs-evidence mutation mutation-ci mutation-baseline mutation-check mutation-check-strict release-readiness manifest manifest-validate manifest-check inventory inventory-check

LOCK_FILE ?= requirements-lock.txt
WHEELHOUSE_DIR ?= wheelhouse
PYTHON_VERSION ?= 3.11
WHEELHOUSE_REPORT ?= artifacts/wheelhouse_report.json

dev-setup:
	python -m pip install --upgrade pip setuptools wheel
	python -m pip install -e ".[dev,test]"
	pre-commit install
	pre-commit autoupdate

quickstart-smoke:
	python -m scripts.check_quickstart_consistency
	python -m pip install -e .
	python -m pip show bnsyn
	bnsyn --help
	bnsyn sleep-stack --help
	bnsyn demo --steps 120 --dt-ms 0.1 --seed 123 --N 32 | python -c "import json,sys; data=json.load(sys.stdin); assert 'demo' in data, 'missing demo key'; print('quickstart demo output validated')"


wheelhouse-build:
	python -m scripts.build_wheelhouse build --lock-file $(LOCK_FILE) --wheelhouse $(WHEELHOUSE_DIR) --python-version $(PYTHON_VERSION)

wheelhouse-validate:
	python -m scripts.build_wheelhouse validate --lock-file $(LOCK_FILE) --wheelhouse $(WHEELHOUSE_DIR) --python-version $(PYTHON_VERSION) --report $(WHEELHOUSE_REPORT)

dev-env-offline: wheelhouse-validate
	python -m pip install --no-index --find-links $(WHEELHOUSE_DIR) -r $(LOCK_FILE)
	python -m pip install --no-index --find-links $(WHEELHOUSE_DIR) --no-deps -e .
	pre-commit install

wheelhouse-clean:
	rm -rf $(WHEELHOUSE_DIR) $(WHEELHOUSE_REPORT)

wheelhouse-report: wheelhouse-validate
	@echo "Wheelhouse report: $(WHEELHOUSE_REPORT)"

test:
	python -m pytest -m "not validation" -q

test-determinism:
	python -m pytest tests/test_determinism.py tests/test_properties_determinism.py -q

test-validation:
	python -m pytest -m validation -q

coverage:
	python -m pytest --cov=bnsyn --cov-report=term-missing:skip-covered --cov-report=xml:coverage.xml -q

coverage-fast:
	python -m pytest -m "not (validation or property)" --cov=bnsyn --cov-report=term-missing --cov-report=xml:coverage.xml -q

coverage-baseline: coverage
	python -m scripts.generate_coverage_baseline --coverage-xml coverage.xml --output quality/coverage_gate.json --minimum-percent 99.0

coverage-gate: coverage
	python -m scripts.check_coverage_gate --coverage-xml coverage.xml --baseline quality/coverage_gate.json


mutation:
	@echo "ðŸ§¬ Running mutation profile (reproducible local workflow step)..."
	@python -m pip install -e ".[test]" -q
	@python -m pip install mutmut==2.4.5 -q
	@python -m scripts.run_mutation_pipeline

mutation-ci:
	@echo "ðŸ§¬ Emitting mutation CI artifacts to local files..."
	@baseline_file=quality/mutation_baseline.json; \
	output_file=.mutation_ci_output; \
	summary_file=.mutation_ci_summary.md; \
	: > $$output_file; \
	: > $$summary_file; \
	GITHUB_OUTPUT=$$output_file GITHUB_STEP_SUMMARY=$$summary_file python -m scripts.mutation_ci_summary --baseline $$baseline_file --write-output --write-summary

mutation-baseline:
	@echo "ðŸ§¬ Running mutation testing to establish baseline..."
	@python -m pip install -e ".[test]" -q
	@python -m pip install mutmut==2.4.5 -q
	@python -m scripts.generate_mutation_baseline

mutation-check:
	@echo "ðŸ§¬ Running mutation testing against baseline..."
	@python -m pip install -e ".[test]" -q
	@python -m pip install mutmut==2.4.5 -q
	@rm -rf .mutmut-cache
	@python -c "import json; baseline=json.load(open('quality/mutation_baseline.json')); print(f\"Baseline: {baseline['baseline_score']}% (tolerance: Â±{baseline['tolerance_delta']}%)\")"
	@python -m scripts.validate_mutation_baseline
	@python -m scripts.run_mutation_pipeline
	@python -m scripts.check_mutation_score --advisory

mutation-check-strict:
	@echo "ðŸ§¬ Running mutation testing against baseline (STRICT MODE)..."
	@python -m pip install -e ".[test]" -q
	@python -m pip install mutmut==2.4.5 -q
	@rm -rf .mutmut-cache
	@python -c "import json; baseline=json.load(open('quality/mutation_baseline.json')); print(f\"Baseline: {baseline['baseline_score']}% (tolerance: Â±{baseline['tolerance_delta']}%)\")"
	@python -m scripts.validate_mutation_baseline
	@python -m scripts.run_mutation_pipeline
	@python -m scripts.check_mutation_score --strict

api-contract:
	python -m scripts.check_api_contract --baseline quality/api_contract_baseline.json

validate-api-maturity:
	python -m scripts.validate_api_maturity

quality: format lint mypy ssot security
	@echo "âœ… All quality checks passed"

format:
	ruff format .
	@echo "Formatted code"

fix:
	ruff check . --fix
	@echo "Fixed lint issues"

lint:
	ruff check .
	pylint src/bnsyn

mypy:
	mypy src --strict --config-file pyproject.toml

ssot:
	python -m scripts.validate_bibliography
	python -m scripts.validate_claims
	python -m scripts.scan_normative_tags
	python -m scripts.validate_pr_gates
	python -m scripts.validate_required_status_contexts
	python -m scripts.sync_required_status_contexts --check
	$(MAKE) inventory-check
	python -m scripts.validate_api_maturity
	$(MAKE) api-contract
	$(MAKE) manifest-check

validate-claims-coverage:
	python -m scripts.validate_claims_coverage --format markdown

docs-evidence:
	python -m scripts.generate_evidence_coverage

security:
	gitleaks detect --redact --verbose --source=.
	pip-audit --desc
	bandit -r src/ -ll

check: format lint mypy coverage ssot security
	@echo "âœ… All checks passed"

docs:
	python -m sphinx -b html docs docs/_build/html
	@echo "Docs built at docs/_build/html"

release-readiness:
	python -m scripts.release_readiness

manifest:
	python -m tools.manifest generate

manifest-validate:
	python -m tools.manifest validate

manifest-check: manifest manifest-validate
	git diff --exit-code -- .github/REPO_MANIFEST.md manifest/repo_manifest.computed.json

inventory:
	python tools/generate_inventory.py

inventory-check:
	python tools/generate_inventory.py --check

clean:
	find . -type d -name __pycache__ -exec rm -rf {} +
	find . -type d -name .pytest_cache -exec rm -rf {} +
	find . -type d -name .mypy_cache -exec rm -rf {} +
	find . -type d -name htmlcov -exec rm -rf {} +
	find . -type f -name .coverage -delete
	find . -type d -name "*.egg-info" -exec rm -rf {} +
	rm -f .mutmut-cache
	rm -rf $(WHEELHOUSE_DIR) $(WHEELHOUSE_REPORT)
	@echo "Cleaned temporary files"
stderr:
---
